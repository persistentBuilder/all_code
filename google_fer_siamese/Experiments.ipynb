{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SiameseGoogleFer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "10\n",
      "2.5702099800109863\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torchvision import transforms\n",
    "\n",
    "t = time.time()\n",
    "train_path = \"data/faceexp-comparison-data-train-public.csv\"\n",
    "test_path = \"data/faceexp-comparison-data-test-public.csv\"\n",
    "transform = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])\n",
    "train_dataset = SiameseGoogleFer(train_path, train_flag=True, divisions=5000, transform=transform)\n",
    "test_dataset = SiameseGoogleFer(test_path, train_flag=False, divisions=5000, transform=transform)\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_dataset.__len__())\n",
    "test_dataset.__len__()\n",
    "import torch \n",
    "from torch.autograd import Variable\n",
    "batch_size = 4\n",
    "\n",
    "from tripletnet import FECNet, EmbeddNet\n",
    "model = EmbeddNet()\n",
    "tnet = FECNet(model)\n",
    "kwargs = {}\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "for batch_idx, (data1, data2, data3) in enumerate(train_loader):\n",
    "    data1, data2, data3 = Variable(data1), Variable(data2), Variable(data3)\n",
    "    dista, distb, distc, embedded_x, embedded_y, embedded_z = tnet(data1, data2, data3)\n",
    "    break\n",
    "embedded_x.size()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from densenet import *\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, growthRate, depth, input_channels, reduction, nClasses, bottleneck):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        nDenseBlocks = (depth-4) // 3\n",
    "        if bottleneck:\n",
    "            nDenseBlocks //= 2\n",
    "\n",
    "        nChannels = 2*growthRate\n",
    "        self.conv1 = nn.Conv2d(input_channels, nChannels, kernel_size=3, padding=1,\n",
    "                               bias=False)\n",
    "        self.dense1 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        nChannels += nDenseBlocks*growthRate\n",
    "        nOutChannels = int(math.floor(nChannels*reduction))\n",
    "        self.trans1 = Transition(nChannels, nOutChannels)\n",
    "\n",
    "        nChannels = nOutChannels\n",
    "        self.dense2 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        nChannels += nDenseBlocks*growthRate\n",
    "        nOutChannels = int(math.floor(nChannels*reduction))\n",
    "        self.trans2 = Transition(nChannels, nOutChannels)\n",
    "\n",
    "        nChannels = nOutChannels\n",
    "        self.dense3 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        nChannels += nDenseBlocks*growthRate\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels)\n",
    "        #self.fc = nn.Linear(128, nClasses)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_dense(self, nChannels, growthRate, nDenseBlocks, bottleneck):\n",
    "        layers = []\n",
    "        for i in range(int(nDenseBlocks)):\n",
    "            if bottleneck:\n",
    "                layers.append(Bottleneck(nChannels, growthRate))\n",
    "            else:\n",
    "                layers.append(SingleLayer(nChannels, growthRate))\n",
    "            nChannels += growthRate\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.trans1(self.dense1(out))\n",
    "        out = self.trans2(self.dense2(out))\n",
    "        out = self.dense3(out)\n",
    "        print(out.size())\n",
    "        # print(out.data.shape)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        print(out.size())\n",
    "        #out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # print(out.data.shape)\n",
    "        #out = F.sigmoid(self.fc(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "comp_resnet_pretrained = InceptionResnetV1(pretrained='vggface2')\n",
    "modules = list(comp_resnet_pretrained.children())[:-8]\n",
    "resnet = nn.Sequential(*modules)\n",
    "densenet = DenseNet(growthRate=64, depth=5, input_channels=896, reduction=0.5, bottleneck=True, nClasses=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 3, 3])\n",
      "torch.Size([4, 32, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 288])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenet(resnet(data1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1792, 5, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1905da4a4348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'train'"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [410]>\n",
      "<Response [404]>\n",
      "<Response [404]>\n",
      "<Response [404]>\n",
      "<Response [404]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "  + Number of params: 27918535\n",
      "loss  after  1  epoch:  1.4227095246315002\n",
      "test accuracy after  1  epoch:  32.142857142857146\n",
      "loss  after  2  epoch:  1.3273468017578125\n",
      "test accuracy after  2  epoch:  35.714285714285715\n",
      "loss  after  3  epoch:  1.1701658964157104\n",
      "test accuracy after  3  epoch:  32.142857142857146\n"
     ]
    }
   ],
   "source": [
    "run train_and_test.py --epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0a304da0f193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "resnet = InceptionResnetV1(pretrained='vggface2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [410]>\n",
      "<Response [404]>\n",
      "<Response [404]>\n",
      "<Response [404]>\n",
      "<Response [404]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n",
      "<Response [410]>\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if False else {}\n",
    "batch_size=4\n",
    "transform = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])\n",
    "train_path = \"data/faceexp-comparison-data-train-public.csv\"\n",
    "test_path = \"data/faceexp-comparison-data-test-public.csv\"\n",
    "train_dataset = SiameseGoogleFer(train_path, train_flag=True, transform=transform)\n",
    "test_dataset = SiameseGoogleFer(test_path, train_flag=False, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tripletnet import FECNet, EmbeddNet\n",
    "model = EmbeddNet()\n",
    "tnet = FECNet(model)\n",
    "for batch_idx, (data1, data2, data3) in enumerate(train_loader):\n",
    "    data1, data2, data3 = Variable(data1), Variable(data2), Variable(data3)\n",
    "    dista, distb, distc, embedded_x, embedded_y, embedded_z = tnet(data1, data2, data3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0119,  0.0215,  0.0509, -0.0129, -0.0075, -0.0220,  0.0671, -0.0386,\n",
       "          0.0093, -0.0005, -0.0224,  0.0014, -0.0047, -0.0448, -0.0154, -0.0338],\n",
       "        [ 0.0093,  0.0433,  0.0337, -0.0034,  0.0161, -0.0100,  0.0040,  0.0010,\n",
       "          0.0424, -0.0313, -0.0732, -0.0305, -0.0524, -0.0471, -0.0571, -0.0421],\n",
       "        [ 0.0280,  0.0102,  0.0265,  0.0034, -0.0402,  0.0233, -0.0097,  0.0020,\n",
       "         -0.0412, -0.0133, -0.0102, -0.0455, -0.0431, -0.0025, -0.0458, -0.0441],\n",
       "        [ 0.0355,  0.0185, -0.0030, -0.0201,  0.0118,  0.0008, -0.0089, -0.0357,\n",
       "         -0.0539, -0.0302, -0.0295, -0.0163, -0.0457, -0.0379, -0.0565, -0.0340]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import TripletLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = TripletLoss(margin=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2055, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(embedded_x, embedded_y, embedded_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def triplet_accuracy(dista, distb, distc):\n",
    "    return numpy.logical_and(dista < distb, dista < distc).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_accuracy(dista.detach().numpy(), distb.detach().numpy(), distc.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1345, 0.1593, 0.1257, 0.1172], grad_fn=<NormBackward1>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0899, 0.0826, 0.1411, 0.1278], grad_fn=<NormBackward1>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1061, 0.1316, 0.1354, 0.1413], grad_fn=<NormBackward1>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for parama in tnet.parameters():\n",
    "    cnt = cnt+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnet.embeddingnet.resnet.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_venv",
   "language": "python",
   "name": "deep_learning_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
